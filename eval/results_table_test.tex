\begin{table*}[t]
\centering
\setlength{\tabcolsep}{3.75pt}
\begin{tabular}{lllllllll}
\toprule
\textbf{Models} & \multicolumn{2}{c}{\textbf{Qwen3-VL-4B}} & \multicolumn{2}{c}{\textbf{Qwen3-VL-8B}} & \multicolumn{2}{c}{\textbf{Qwen3-VL-30B}} & \multicolumn{2}{c}{\textbf{GPT-5.2}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9}
\textbf{Variants} & \multicolumn{1}{c}{Instruct} & \multicolumn{1}{c}{Thinking} & \multicolumn{1}{c}{Instruct} & \multicolumn{1}{c}{Thinking} & \multicolumn{1}{c}{Instruct} & \multicolumn{1}{c}{Thinking} & \multicolumn{1}{c}{Low} & \multicolumn{1}{c}{High} \\
\midrule
Comment Only & \textbf{49.7} & 38.5 & \textbf{50.9} & 41.6 & 50.4 & 46.4 & 54.5 & 55.0 \\
\quad +Discussion & 49.6 {\tiny (-0.1)} & 40.2 {\tiny (+1.7)} & 50.6 {\tiny (-0.3)} & 44.4 {\tiny (+2.8)} & 51.7 {\tiny (+1.3)} & 48.0 {\tiny (+1.6)} & 55.1 {\tiny (+0.6)} & 55.8 {\tiny (+0.8)} \\
\quad\quad +Submission & 47.8 {\tiny (-1.8)} & 45.4 {\tiny (+5.2)} & 49.8 {\tiny (-0.8)} & 46.9 {\tiny (+2.5)} & 52.3 {\tiny (+0.6)} & 48.9 {\tiny (+0.9)} & 57.1 {\tiny (+2.0)} & 57.5 {\tiny (+1.7)} \\
\quad\quad\quad +User & 48.4 {\tiny (+0.6)} & 44.7 {\tiny (-0.7)} & 50.2 {\tiny (+0.4)} & \textbf{46.9} {\tiny (+0.0)} & 51.7 {\tiny (-0.6)} & \textbf{49.6} {\tiny (+0.7)} & \textbf{57.8} {\tiny (+0.7)} & 57.6 {\tiny (+0.1)} \\
\quad\quad\quad\quad +Images & 47.9 {\tiny (-0.5)} & \textbf{45.4} {\tiny (+0.7)} & 50.3 {\tiny (+0.1)} & 45.0 {\tiny (-1.9)} & \textbf{52.6} {\tiny (+0.9)} & 48.8 {\tiny (-0.8)} & 57.3 {\tiny (-0.5)} & \textbf{58.2} {\tiny (+0.6)} \\
\midrule
No Moderation & \multicolumn{8}{c}{50.0} \\
\bottomrule
\end{tabular}
\caption{Overall accuracy (\%) across different models and contexts on the test set. Numbers in parentheses indicate differences compared to accuracy values in the previous row. All values have 95\% CI of $\pm 1.1\%$. See the Appendix for a breakdown of moderated and unmoderated accuracy.}
\label{tab:results-across-contexts}
\end{table*}