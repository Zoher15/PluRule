#!/usr/bin/env python3
"""
Pipeline Validation Script

Compares summary/manifest counts against actual file counts on disk to detect
data drift caused by partial re-runs of pipeline stages. Reports mismatches
that could lead to stale data being consumed by downstream stages.

Usage:
    python pipeline/validate_pipeline.py
    python pipeline/validate_pipeline.py --stage 3    # Validate specific stage
    python pipeline/validate_pipeline.py --verbose     # Show per-file details
"""

import sys
import os
import glob
import argparse
from datetime import datetime
from collections import defaultdict

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import PATHS
from utils.files import read_json_file


def validate_stage3(verbose=False):
    """Validate Stage 3: Match Rules consistency."""
    issues = []
    info = []

    output_dir = PATHS['matched_comments']

    # Count files on disk
    matrix_files = glob.glob(os.path.join(output_dir, '*_similarity_matrix.pt'))
    match_files = glob.glob(os.path.join(output_dir, '*_match.jsonl.zst'))
    stats_files = glob.glob(os.path.join(output_dir, '*_stats.json'))

    info.append(f"Files on disk: {len(matrix_files)} matrices, {len(match_files)} match files, {len(stats_files)} stats files")

    # Load summary
    summary_file = os.path.join(PATHS['data'], 'stage3_matching_summary.json')
    if not os.path.exists(summary_file):
        issues.append("CRITICAL: stage3_matching_summary.json not found")
        return issues, info

    summary = read_json_file(summary_file)
    summary_subreddits = {s['subreddit'] for s in summary.get('subreddit_stats', [])}
    summary_with_matches = {s['subreddit'] for s in summary.get('subreddit_stats', [])
                            if s.get('matched_comments', 0) > 0}

    info.append(f"Summary: {len(summary_subreddits)} subreddits total, {len(summary_with_matches)} with matches")

    # Check matrix count vs summary
    if len(matrix_files) != len(summary_subreddits):
        issues.append(f"Matrix count mismatch: {len(matrix_files)} on disk vs {len(summary_subreddits)} in summary")

    # Check match file subreddits vs summary subreddits with matches
    match_subreddits = {os.path.basename(f).replace('_match.jsonl.zst', '') for f in match_files}
    extra_match_files = match_subreddits - summary_with_matches
    missing_match_files = summary_with_matches - match_subreddits

    if extra_match_files:
        issues.append(f"CRITICAL: {len(extra_match_files)} match files on disk NOT in summary (stale from previous runs)")
        if verbose:
            for sub in sorted(extra_match_files)[:20]:
                issues.append(f"  - {sub}_match.jsonl.zst (stale)")

    if missing_match_files:
        issues.append(f"WARNING: {len(missing_match_files)} subreddits in summary missing match files on disk")
        if verbose:
            for sub in sorted(missing_match_files)[:20]:
                issues.append(f"  - {sub} (missing)")

    # Check date consistency of match files
    if match_files:
        mtimes = defaultdict(list)
        for f in match_files:
            mtime = os.path.getmtime(f)
            date_str = datetime.fromtimestamp(mtime).strftime('%Y-%m-%d')
            mtimes[date_str].append(os.path.basename(f))

        if len(mtimes) > 1:
            issues.append(f"WARNING: Match files span {len(mtimes)} different dates: {sorted(mtimes.keys())}")
            for date, files in sorted(mtimes.items()):
                info.append(f"  {date}: {len(files)} match files")

    # Check submission IDs manifest
    sub_ids_file = os.path.join(PATHS['data'], 'stage3_subreddit_submission_ids.json')
    if os.path.exists(sub_ids_file):
        sub_ids_data = read_json_file(sub_ids_file)
        manifest_subreddits = set(sub_ids_data.get('subreddit_submission_ids', {}).keys())
        if manifest_subreddits != summary_with_matches:
            diff = manifest_subreddits.symmetric_difference(summary_with_matches)
            issues.append(f"WARNING: Submission IDs manifest differs from summary by {len(diff)} subreddits")

    # Verify total_matched in summary vs sum of subreddit stats
    reported_total = summary.get('total_matched', 0)
    computed_total = sum(s.get('matched_comments', 0) for s in summary.get('subreddit_stats', []))
    if reported_total != computed_total:
        issues.append(f"WARNING: Summary total_matched ({reported_total}) != sum of subreddit stats ({computed_total})")

    return issues, info


def validate_stage5(verbose=False):
    """Validate Stage 5: Build Trees and Threads consistency."""
    issues = []
    info = []

    trees_dir = PATHS['comment_trees']
    threads_dir = PATHS['discussion_threads']

    # Count files on disk
    tree_files = glob.glob(os.path.join(trees_dir, '*_comment_trees.pkl')) if os.path.exists(trees_dir) else []
    thread_files = glob.glob(os.path.join(threads_dir, '*_discussion_threads.pkl')) if os.path.exists(threads_dir) else []

    tree_subreddits = {os.path.basename(f).replace('_comment_trees.pkl', '') for f in tree_files}
    thread_subreddits = {os.path.basename(f).replace('_discussion_threads.pkl', '') for f in thread_files}

    info.append(f"Files on disk: {len(tree_files)} tree files, {len(thread_files)} thread files")

    # Tree and thread files should match
    if tree_subreddits != thread_subreddits:
        only_trees = tree_subreddits - thread_subreddits
        only_threads = thread_subreddits - tree_subreddits
        if only_trees:
            issues.append(f"WARNING: {len(only_trees)} subreddits have trees but no threads")
        if only_threads:
            issues.append(f"WARNING: {len(only_threads)} subreddits have threads but no trees")

    # Load summary
    summary_file = os.path.join(PATHS['data'], 'stage5_trees_and_threads_summary.json')
    if not os.path.exists(summary_file):
        issues.append("CRITICAL: stage5_trees_and_threads_summary.json not found")
        return issues, info

    summary = read_json_file(summary_file)
    summary_stats = summary.get('subreddit_stats', [])
    summary_subreddits = {s['subreddit'] for s in summary_stats if s.get('status') == 'completed'}

    info.append(f"Summary: {len(summary_subreddits)} completed subreddits")

    # Check for stale files not in summary
    extra_trees = tree_subreddits - summary_subreddits
    extra_threads = thread_subreddits - summary_subreddits

    if extra_trees:
        issues.append(f"CRITICAL: {len(extra_trees)} tree files on disk NOT in summary (stale from previous runs)")
        if verbose:
            for sub in sorted(extra_trees)[:20]:
                issues.append(f"  - {sub}_comment_trees.pkl (stale)")

    if extra_threads:
        issues.append(f"CRITICAL: {len(extra_threads)} thread files on disk NOT in summary (stale from previous runs)")

    # Check date consistency
    for label, files in [("tree", tree_files), ("thread", thread_files)]:
        if files:
            mtimes = defaultdict(int)
            for f in files:
                mtime = os.path.getmtime(f)
                date_str = datetime.fromtimestamp(mtime).strftime('%Y-%m-%d')
                mtimes[date_str] += 1

            if len(mtimes) > 1:
                issues.append(f"WARNING: {label.capitalize()} files span {len(mtimes)} different dates: {sorted(mtimes.keys())}")
                for date, count in sorted(mtimes.items()):
                    info.append(f"  {date}: {count} {label} files")

    # Cross-validate with Stage 3
    stage3_summary_file = os.path.join(PATHS['data'], 'stage3_matching_summary.json')
    if os.path.exists(stage3_summary_file):
        stage3_summary = read_json_file(stage3_summary_file)
        stage3_with_matches = {s['subreddit'] for s in stage3_summary.get('subreddit_stats', [])
                                if s.get('matched_comments', 0) > 0}
        extra_vs_stage3 = tree_subreddits - stage3_with_matches
        if extra_vs_stage3:
            issues.append(f"CRITICAL: {len(extra_vs_stage3)} tree files for subreddits NOT in Stage 3 manifest")

    return issues, info


def validate_stage4(verbose=False):
    """Validate Stage 4: Organized Comments consistency."""
    issues = []
    info = []

    organized_dir = PATHS['organized_comments']
    if not os.path.exists(organized_dir):
        issues.append("WARNING: organized_comments directory not found")
        return issues, info

    # Count subreddit dirs on disk
    subreddit_dirs = [d for d in os.listdir(organized_dir)
                      if os.path.isdir(os.path.join(organized_dir, d))]

    info.append(f"Files on disk: {len(subreddit_dirs)} subreddit directories")

    # Cross-validate with Stage 3 submission IDs manifest
    sub_ids_file = os.path.join(PATHS['data'], 'stage3_subreddit_submission_ids.json')
    if os.path.exists(sub_ids_file):
        sub_ids_data = read_json_file(sub_ids_file)
        manifest_subreddits = set(sub_ids_data.get('subreddit_submission_ids', {}).keys())
        extra_dirs = set(subreddit_dirs) - manifest_subreddits
        missing_dirs = manifest_subreddits - set(subreddit_dirs)

        if extra_dirs:
            issues.append(f"WARNING: {len(extra_dirs)} organized_comments dirs NOT in Stage 3 submission IDs manifest (potentially stale)")
        if missing_dirs:
            issues.append(f"WARNING: {len(missing_dirs)} subreddits in manifest missing organized_comments dirs")

    # Load Stage 4 summary
    stage4_summary_file = os.path.join(PATHS['data'], 'stage4_submission_comment_collection_stats.json')
    if os.path.exists(stage4_summary_file):
        stage4_summary = read_json_file(stage4_summary_file)
        summary_subreddits = set()
        for stats in stage4_summary.get('subreddit_stats', []):
            sub = stats.get('subreddit')
            if sub:
                summary_subreddits.add(sub)
        info.append(f"Stage 4 summary: {len(summary_subreddits)} subreddits")

        extra_vs_summary = set(subreddit_dirs) - summary_subreddits
        if extra_vs_summary:
            issues.append(f"WARNING: {len(extra_vs_summary)} organized_comments dirs NOT in Stage 4 summary")

    return issues, info


def validate_stage6(verbose=False):
    """Validate Stage 6: Submissions consistency."""
    issues = []
    info = []

    submissions_dir = PATHS['submissions']
    if not os.path.exists(submissions_dir):
        issues.append("WARNING: submissions directory not found")
        return issues, info

    submission_files = glob.glob(os.path.join(submissions_dir, '*_submissions.zst'))
    submission_subreddits = {os.path.basename(f).replace('_submissions.zst', '') for f in submission_files}

    info.append(f"Files on disk: {len(submission_files)} submission files")

    # Load Stage 6 summary
    summary_file = os.path.join(PATHS['data'], 'stage6_submission_collection_stats.json')
    if os.path.exists(summary_file):
        summary = read_json_file(summary_file)
        summary_subreddits = set()
        for stats in summary.get('subreddit_stats', []):
            sub = stats.get('subreddit')
            if sub:
                summary_subreddits.add(sub)

        extra = submission_subreddits - summary_subreddits
        if extra:
            issues.append(f"WARNING: {len(extra)} submission files on disk NOT in Stage 6 summary (potentially stale)")

    # Cross-validate with Stage 5
    stage5_summary_file = os.path.join(PATHS['data'], 'stage5_trees_and_threads_summary.json')
    if os.path.exists(stage5_summary_file):
        stage5_summary = read_json_file(stage5_summary_file)
        stage5_subreddits = {s['subreddit'] for s in stage5_summary.get('subreddit_stats', [])
                             if s.get('status') == 'completed'}
        extra_vs_stage5 = submission_subreddits - stage5_subreddits
        if extra_vs_stage5:
            issues.append(f"WARNING: {len(extra_vs_stage5)} submission files for subreddits NOT in Stage 5 summary")

    return issues, info


def validate_stage8(verbose=False):
    """Validate Stage 8: Dataset consistency."""
    issues = []
    info = []

    # Load Stage 7 successful IDs
    stage7_file = os.path.join(PATHS['data'], 'stage7_successful_submission_ids.json')
    if not os.path.exists(stage7_file):
        info.append("Stage 7 successful IDs not found (stage 7 may not have run yet)")
        return issues, info

    stage7_data = read_json_file(stage7_file)
    if isinstance(stage7_data, dict) and 'subreddit_submission_ids' in stage7_data:
        stage7_subreddits = set(stage7_data['subreddit_submission_ids'].keys())
    elif isinstance(stage7_data, dict):
        stage7_subreddits = set(stage7_data.keys())
    else:
        stage7_subreddits = set()

    # Check that required files exist for each subreddit in Stage 7
    missing_trees = []
    missing_threads = []
    missing_submissions = []

    for subreddit in stage7_subreddits:
        tree_file = os.path.join(PATHS['comment_trees'], f"{subreddit}_comment_trees.pkl")
        thread_file = os.path.join(PATHS['discussion_threads'], f"{subreddit}_discussion_threads.pkl")
        submission_file = os.path.join(PATHS['submissions'], f"{subreddit}_submissions.zst")

        if not os.path.exists(tree_file):
            missing_trees.append(subreddit)
        if not os.path.exists(thread_file):
            missing_threads.append(subreddit)
        if not os.path.exists(submission_file):
            missing_submissions.append(subreddit)

    if missing_trees:
        issues.append(f"WARNING: {len(missing_trees)} Stage 7 subreddits missing tree files")
    if missing_threads:
        issues.append(f"WARNING: {len(missing_threads)} Stage 7 subreddits missing thread files")
    if missing_submissions:
        issues.append(f"WARNING: {len(missing_submissions)} Stage 7 subreddits missing submission files")

    info.append(f"Stage 7: {len(stage7_subreddits)} subreddits with successful submissions")

    return issues, info


VALIDATORS = {
    3: ("Stage 3: Match Rules", validate_stage3),
    4: ("Stage 4: Organized Comments", validate_stage4),
    5: ("Stage 5: Trees & Threads", validate_stage5),
    6: ("Stage 6: Submissions", validate_stage6),
    8: ("Stage 8: Dataset", validate_stage8),
}


def main():
    parser = argparse.ArgumentParser(description="Validate pipeline data consistency across stages")
    parser.add_argument("--stage", type=int, help="Validate a specific stage only")
    parser.add_argument("--verbose", action="store_true", help="Show per-file details")
    args = parser.parse_args()

    print("=" * 70)
    print("Pipeline Data Consistency Validation")
    print(f"Run at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)

    total_issues = 0
    stages_to_validate = {args.stage: VALIDATORS[args.stage]} if args.stage else VALIDATORS

    for stage_num, (label, validator) in sorted(stages_to_validate.items()):
        print(f"\n{'â”€' * 70}")
        print(f"  {label}")
        print(f"{'â”€' * 70}")

        issues, info_lines = validator(verbose=args.verbose)

        for line in info_lines:
            print(f"  â„¹ï¸  {line}")

        if issues:
            for issue in issues:
                if issue.startswith("CRITICAL"):
                    print(f"  ðŸ”´ {issue}")
                elif issue.startswith("WARNING"):
                    print(f"  ðŸŸ¡ {issue}")
                else:
                    print(f"     {issue}")
            total_issues += len([i for i in issues if i.startswith(("CRITICAL", "WARNING"))])
        else:
            print(f"  âœ… No issues found")

    print(f"\n{'=' * 70}")
    if total_issues > 0:
        print(f"  âš ï¸  Found {total_issues} issue(s) across validated stages")
        print(f"  Run with --verbose for more details")
    else:
        print(f"  âœ… All validated stages are consistent")
    print(f"{'=' * 70}")

    return 1 if total_issues > 0 else 0


if __name__ == "__main__":
    exit(main())
